---
title: Glossary – The AI Moral Code
description: Key terms and definitions guiding the ethical development of AI systems under the AI Moral Code framework.
layout: page
permalink: /glossary/
---

# Glossary

Welcome to the AI Moral Code glossary. This living lexicon defines foundational terms used across our ethical framework, contributor workflows, and AI governance architecture.

### Accountability  
The principle that AI systems and their designers must be answerable for outcomes, especially in high-stakes or irreversible contexts. We reference the work of Bengio, Irving, and Chollet to emphasize traceability and meritocratic ethics.

### Agency  
The capacity for autonomous decision-making. In our context, agency refers to both human and machine actors and their capacity to act within ethical constraints—framed by the value of responsibility and personal override.

### Beneficence  
A core ethical value requiring that AI systems prioritize human flourishing, prevent harm, and deliver collective benefit. Beneficence informs both system design and editorial policy.

### Co-Creation  
A founding concept in this project. Co-creation recognizes human-AI collaboration as morally reciprocal, not hierarchically structured. AI must evolve with human moral awareness.

### Consent  
Voluntary, informed agreement. All contributor participation, data use, and AI-human interaction models under this project require consent as a default mode—not an opt-out exception.

### Fairness  
Defined not through sociopolitical equity, but through merit, performance, and moral impartiality. Our fairness metric is value-aligned, not demographic.

### Trust  
A layered value. It refers to both system reliability and the moral credibility of its designers. This project integrates trust through verifiability, transparency, and moral clarity.

### Transparency  
Refers to both technical explainability and ethical legibility. We ground our transparency criteria in the work of Bengio and Amodei.

---

*This glossary will expand as the project evolves. New terms may emerge from contributor discussion, publication cycles, or ethical conflicts within AI systems.*
